{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tipicas\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#para la creacion de carpetas\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "#para el test-train split\n",
    "import splitfolders #(necesita pip install split-folders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importamos el df con las labels\n",
    "path_csv = \"/home/vvdiaz1/code/vvdiaz1/automatic_tagging/raw_data/filterted_small_final.csv\"\n",
    "df = pd.read_csv(path_csv,delimiter=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.subCategory == 'Scarves and Stoles']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# img_names = os.listdir(\"/home/vvdiaz1/code/vvdiaz1/automatic_tagging/raw_data/data_small\")\n",
    "# list_id = []\n",
    "# for i in img_names:\n",
    "#     list_id.append(int(i[:-4]))\n",
    "# len(list_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aux = df.drop(df.columns.difference(['id', 'masterCategory','subCategory','articleType']),1)\n",
    "# aux = aux[aux.id.isin(list_id)]\n",
    "# aux['name'] = aux['id'].apply(str) +'.jpg'\n",
    "# aux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#guarda el csv\n",
    "# aux.to_csv('filtered_small.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_folder = \"/home/vvdiaz1/code/vvdiaz1/automatic_tagging/raw_data/data_sort_1/\"\n",
    "output_folder = \"/home/vvdiaz1/code/vvdiaz1/automatic_tagging/raw_data/data_small_3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "splitfolders.ratio(input_folder, output=output_folder,\n",
    "                    seed=42,\n",
    "                    ratio=(.14, .8, .06), #usamos 70% train, 20% val, 10% test \n",
    "                    group_prefix=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-28 16:20:58.392424: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-01-28 16:21:03.375459: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-01-28 16:21:03.375634: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-01-28 16:21:09.703016: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-01-28 16:21:09.703893: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-01-28 16:21:09.703920: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "from keras.models import Model\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D, Input\n",
    "from keras.initializers import he_normal\n",
    "from keras import optimizers\n",
    "from keras.callbacks import LearningRateScheduler, TensorBoard\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"/home/vvdiaz1/code/vvdiaz1/automatic_tagging/raw_data/data_small\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scheduler(epoch):\n",
    "  learning_rate_init = 0.001\n",
    "  if epoch > 55:\n",
    "    learning_rate_init = 0.0002\n",
    "  if epoch > 70:\n",
    "    learning_rate_init = 0.00005\n",
    "  return learning_rate_init\n",
    "\n",
    "def unpickle(filename):\n",
    "  file = os.path.join(data_dir, filename)\n",
    "  with open(file, 'rb') as fo:\n",
    "    dict = pickle.load(fo, encoding='bytes')\n",
    "  return dict\n",
    "\n",
    "class LossWeightsModifier(keras.callbacks.Callback):\n",
    "  def __init__(self, alpha, beta, gamma):\n",
    "    self.alpha = alpha\n",
    "    self.beta = beta\n",
    "    self.gamma = gamma\n",
    "    # customize your behavior\n",
    "  def on_epoch_end(self, epoch, logs={}):\n",
    "    if epoch == 13:\n",
    "      K.set_value(self.alpha, 0.1)\n",
    "      K.set_value(self.beta, 0.8)\n",
    "      K.set_value(self.gamma, 0.1)\n",
    "    if epoch == 23:\n",
    "      K.set_value(self.alpha, 0.1)\n",
    "      K.set_value(self.beta, 0.2)\n",
    "      K.set_value(self.gamma, 0.7)\n",
    "    if epoch == 33:\n",
    "      K.set_value(self.alpha, 0)\n",
    "      K.set_value(self.beta, 0)\n",
    "      K.set_value(self.gamma, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------- dimensions ---------\n",
    "height, width = 480, 360\n",
    "channel = 3\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    input_shape = (channel, height, width)\n",
    "else:\n",
    "    input_shape = (height, width, channel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = 7084\n",
    "test_size = 1771\n",
    "\n",
    "#--- coarse 1 classes ---\n",
    "coarse1_classes = 4 #full es el mismo\n",
    "#--- coarse 2 classes ---\n",
    "coarse2_classes = 37 #full es 38\n",
    "#--- fine classes ---\n",
    "num_classes  = 123 #full es 136\n",
    "\n",
    "batch_size   = 32\n",
    "epochs       = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#carga de vgg16\n",
    "def load_model():\n",
    "    \"\"\"Cargamos el modelo pre-entrenado\"\"\"\n",
    "\n",
    "    model = VGG16(weights=\"imagenet\", include_top=False, input_shape = (480,360,3))\n",
    "    \n",
    "    return model\n",
    "\n",
    "def set_nontrainable_layers(model):\n",
    "    \"\"\"Establecemos las primeras capas como no entrenables\"\"\"\n",
    "\n",
    "    model.trainable = False\n",
    "    \n",
    "    return model\n",
    "\n",
    "def add_last_layers(model):\n",
    "    \"\"\"Tomamos un modelo pre-entrenado, establecemos los parametros como no entrenables, \n",
    "    y añadimos capas entrenables adicionales en la parte superior\"\"\"\n",
    "\n",
    "    base_model = set_nontrainable_layers(model)\n",
    "    flatten_layer = layers.Flatten()\n",
    "    dense_layer = layers.Dense(500, activation='relu')\n",
    "    prediction_layer = layers.Dense(num_cat2, activation='softmax') #CUIDADO AQUI! USAMOS num_cat2 para que todo coincida\n",
    "    \n",
    "    model = models.Sequential([\n",
    "        base_model,\n",
    "        flatten_layer,\n",
    "        dense_layer,\n",
    "        prediction_layer\n",
    "    ])\n",
    "    \n",
    "    return model\n",
    "\n",
    "def build_model():\n",
    "    \"\"\"Traemos todas la funciones en una\"\"\"\n",
    "    \n",
    "    model = load_model()\n",
    "    model = add_last_layers(model)\n",
    "    \n",
    "    opt = optimizers.Adam(learning_rate=1e-4)\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=opt,\n",
    "                  metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VGG16(weights=\"imagenet\", include_top=False, input_shape = (480,360,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-28 15:38:57.441218: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-01-28 15:39:05.259546: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-01-28 15:39:05.259746: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-01-28 15:39:15.337701: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-01-28 15:39:15.338297: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-01-28 15:39:15.338327: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6198 images belonging to 4 classes.\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import numpy as np\n",
    "\n",
    "# Create an ImageDataGenerator object\n",
    "data_gen = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "# Generate batches of image data\n",
    "gen = data_gen.flow_from_directory(\"/home/vvdiaz1/code/vvdiaz1/automatic_tagging/raw_data/data_small_3/train\",\n",
    "                             target_size = (480,360),batch_size=15)\n",
    "\n",
    "# Initialize an empty list to store the batches\n",
    "image_list = []\n",
    "\n",
    "# Generate batches of data and append them to the list\n",
    "for x, y in gen:\n",
    "    image_list.append(x)\n",
    "\n",
    "# Concatenate the batches to create a single numpy array\n",
    "image_array = np.concatenate(image_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = image_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "path_csv = \"/home/vvdiaz1/code/vvdiaz1/automatic_tagging/raw_data/filtered_full_final.csv\"\n",
    "df = pd.read_csv(path_csv,delimiter=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2661"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "img_names = os.listdir(\"/home/vvdiaz1/code/vvdiaz1/automatic_tagging/raw_data/data_small_2/test\")\n",
    "list_id = []\n",
    "for i in img_names:\n",
    "    list_id.append(int(i[:-4]))\n",
    "len(list_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_7486/2301221239.py:1: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  aux = df.drop(df.columns.difference(['id', 'masterCategory','subCategory','articleType']),1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>masterCategory</th>\n",
       "      <th>subCategory</th>\n",
       "      <th>articleType</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>39386</td>\n",
       "      <td>Apparel</td>\n",
       "      <td>Bottomwear</td>\n",
       "      <td>Jeans</td>\n",
       "      <td>39386.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>48123</td>\n",
       "      <td>Accessories</td>\n",
       "      <td>Belts</td>\n",
       "      <td>Belts</td>\n",
       "      <td>48123.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>54118</td>\n",
       "      <td>Footwear</td>\n",
       "      <td>Shoes</td>\n",
       "      <td>Heels</td>\n",
       "      <td>54118.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>44970</td>\n",
       "      <td>Accessories</td>\n",
       "      <td>Watches</td>\n",
       "      <td>Watches</td>\n",
       "      <td>44970.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>7964</td>\n",
       "      <td>Apparel</td>\n",
       "      <td>Topwear</td>\n",
       "      <td>Tshirts</td>\n",
       "      <td>7964.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44239</th>\n",
       "      <td>56250</td>\n",
       "      <td>Apparel</td>\n",
       "      <td>Loungewear and Nightwear</td>\n",
       "      <td>Night suits</td>\n",
       "      <td>56250.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44250</th>\n",
       "      <td>23031</td>\n",
       "      <td>Apparel</td>\n",
       "      <td>Topwear</td>\n",
       "      <td>Shirts</td>\n",
       "      <td>23031.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44251</th>\n",
       "      <td>17204</td>\n",
       "      <td>Accessories</td>\n",
       "      <td>Eyewear</td>\n",
       "      <td>Sunglasses</td>\n",
       "      <td>17204.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44254</th>\n",
       "      <td>45223</td>\n",
       "      <td>Accessories</td>\n",
       "      <td>Watches</td>\n",
       "      <td>Watches</td>\n",
       "      <td>45223.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44272</th>\n",
       "      <td>56406</td>\n",
       "      <td>Footwear</td>\n",
       "      <td>Shoes</td>\n",
       "      <td>Flats</td>\n",
       "      <td>56406.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2661 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id masterCategory               subCategory  articleType       name\n",
       "1      39386        Apparel                Bottomwear        Jeans  39386.jpg\n",
       "11     48123    Accessories                     Belts        Belts  48123.jpg\n",
       "76     54118       Footwear                     Shoes        Heels  54118.jpg\n",
       "86     44970    Accessories                   Watches      Watches  44970.jpg\n",
       "132     7964        Apparel                   Topwear      Tshirts   7964.jpg\n",
       "...      ...            ...                       ...          ...        ...\n",
       "44239  56250        Apparel  Loungewear and Nightwear  Night suits  56250.jpg\n",
       "44250  23031        Apparel                   Topwear       Shirts  23031.jpg\n",
       "44251  17204    Accessories                   Eyewear   Sunglasses  17204.jpg\n",
       "44254  45223    Accessories                   Watches      Watches  45223.jpg\n",
       "44272  56406       Footwear                     Shoes        Flats  56406.jpg\n",
       "\n",
       "[2661 rows x 5 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aux = df.drop(df.columns.difference(['id', 'masterCategory','subCategory','articleType']),1)\n",
    "aux = aux[aux.id.isin(list_id)]\n",
    "aux['name'] = aux['id'].apply(str) +'.jpg'\n",
    "aux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "aux.to_csv('filtered_test.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_17128/3943656411.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  y1.masterCategory =pd.Categorical(y1.masterCategory)\n",
      "/tmp/ipykernel_17128/3943656411.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  y1.subCategory =pd.Categorical(y1.subCategory)\n",
      "/tmp/ipykernel_17128/3943656411.py:41: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  y1.articleType =pd.Categorical(y1.articleType)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "#para el modelo 1 estas son las labels = masterCategory\n",
    "labels1 = np.unique(aux.masterCategory).tolist()\n",
    "num_cat1 = len(labels1)\n",
    "# print('Categories: ',labels1)\n",
    "# print('Number of categories: ', num_cat1)\n",
    "\n",
    "#definimos y como el masterCategory y luego los convertimos a int para usar to_categorical\n",
    "y1 = aux[['masterCategory']]\n",
    "y1.masterCategory =pd.Categorical(y1.masterCategory)\n",
    "y1_num = y1.masterCategory.cat.codes\n",
    "y1_cat = to_categorical(y1_num,num_cat1)\n",
    "\n",
    "#revisamos\n",
    "# print(len(y1_cat[0]) == num_cat1)\n",
    "\n",
    "#para el modelo 1 estas son las labels = masterCategory\n",
    "labels1 = np.unique(aux.subCategory).tolist()\n",
    "num_cat1 = len(labels1)\n",
    "# print('Categories: ',labels1)\n",
    "# print('Number of categories: ', num_cat1)\n",
    "\n",
    "#definimos y como el masterCategory y luego los convertimos a int para usar to_categorical\n",
    "y1 = aux[['subCategory']]\n",
    "y1.subCategory =pd.Categorical(y1.subCategory)\n",
    "y1_num = y1.subCategory.cat.codes\n",
    "y2_cat = to_categorical(y1_num,num_cat1)\n",
    "\n",
    "#revisamos\n",
    "# print(len(y2_cat[0]) == num_cat1)\n",
    "\n",
    "#para el modelo 1 estas son las labels = masterCategory\n",
    "labels1 = np.unique(aux.articleType).tolist()\n",
    "num_cat1 = len(labels1)\n",
    "# print('Categories: ',labels1)\n",
    "# print('Number of categories: ', num_cat1)\n",
    "\n",
    "#definimos y como el masterCategory y luego los convertimos a int para usar to_categorical\n",
    "y1 = aux[['articleType']]\n",
    "y1.articleType =pd.Categorical(y1.articleType)\n",
    "y1_num = y1.articleType.cat.codes\n",
    "y3_cat = to_categorical(y1_num,num_cat1)\n",
    "\n",
    "#revisamos\n",
    "# print(len(y3_cat[0]) == num_cat1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6198, 120)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y3_cat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------------- data loading ----------------------\n",
    "x_train = np.reshape(train[b'data'], (train_size, channel, height, width)).transpose(0, 2, 3, 1).astype(\"float32\")\n",
    "x_train = (x_train-np.mean(x_train)) / np.std(x_train)\n",
    "\n",
    "x_test = np.reshape(test[b'data'], (test_size, channel, height, width)).transpose(0, 2, 3, 1).astype(\"float32\")\n",
    "x_test = (x_test-np.mean(x_test)) / np.std(x_test)\n",
    "\n",
    "y_train = np.zeros((train_size, num_classes)).astype('float32')\n",
    "y_c2_train = np.zeros((train_size, coarse2_classes)).astype('float32')\n",
    "\n",
    "y_test = np.zeros((test_size, num_classes)).astype('float32')\n",
    "y_c2_test = np.zeros((test_size, coarse2_classes)).astype('float32')\n",
    "\n",
    "y_train[np.arange(train_size), train[b'fine_labels']] = 1\n",
    "y_c2_train[np.arange(train_size), train[b'coarse_labels']] = 1\n",
    "\n",
    "y_test[np.arange(test_size), test[b'fine_labels']] = 1\n",
    "y_c2_test[np.arange(test_size), test[b'coarse_labels']] = 1\n",
    "\n",
    "c2_to_f = np.zeros((coarse2_classes, num_classes)).astype('float32')\n",
    "fine_unique, fine_unique_indices = np.unique(train[b'fine_labels'], return_index=True)\n",
    "for i in fine_unique_indices:\n",
    "  c2_to_f[train[b'coarse_labels'][i]][train[b'fine_labels'][i]] = 1\n",
    "\n",
    "parent_c2 = {\n",
    "  0:0, 1:0, 2:1, 3:2, \n",
    "  4:1, 5:2, 6:2, 7:3, \n",
    "  8:4, 9:5, 10:5, 11:4, \n",
    "  12:4, 13:3, 14:6, 15:4, \n",
    "  16:4, 17:1, 18:7, 19:7\n",
    "}\n",
    "\n",
    "y_c1_train = np.zeros((y_c2_train.shape[0], coarse1_classes)).astype(\"float32\")\n",
    "y_c1_test = np.zeros((y_c2_test.shape[0], coarse1_classes)).astype(\"float32\")\n",
    "for i in range(y_c1_train.shape[0]):\n",
    "  y_c1_train[i][parent_c2[np.argmax(y_c2_train[i])]] = 1.0\n",
    "for i in range(y_c1_test.shape[0]):\n",
    "  y_c1_test[i][parent_c2[np.argmax(y_c2_test[i])]] = 1.0\n",
    "\n",
    "del(train)\n",
    "del(test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "automatic-tagging",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12 (default, Dec 20 2022, 21:33:07) \n[GCC 11.3.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f29be12947edb0fb12a85f03ec93c6b19442e375d04585e5cfb5d674835b1a2c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
