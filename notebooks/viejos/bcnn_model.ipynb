{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------------------------------\n",
    "# Author: Xinqi Zhu\n",
    "# Please cite paper https://arxiv.org/abs/1709.09890 if you use this code\n",
    "#------------------------------------\n",
    "import keras\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D, Input\n",
    "from keras.initializers import he_normal\n",
    "from keras import optimizers\n",
    "from keras.callbacks import LearningRateScheduler, TensorBoard\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras import backend as K\n",
    "\n",
    "#-----data dir----\n",
    "data_dir = \"./data\"\n",
    "#-----------------\n",
    "\n",
    "def scheduler(epoch):\n",
    "  learning_rate_init = 0.001\n",
    "  if epoch > 55:\n",
    "    learning_rate_init = 0.0002\n",
    "  if epoch > 70:\n",
    "    learning_rate_init = 0.00005\n",
    "  return learning_rate_init\n",
    "\n",
    "def unpickle(filename):\n",
    "  file = os.path.join(data_dir, filename)\n",
    "  with open(file, 'rb') as fo:\n",
    "    dict = pickle.load(fo, encoding='bytes')\n",
    "  return dict\n",
    "\n",
    "class LossWeightsModifier(keras.callbacks.Callback):\n",
    "  def __init__(self, alpha, beta, gamma):\n",
    "    self.alpha = alpha\n",
    "    self.beta = beta\n",
    "    self.gamma = gamma\n",
    "    # customize your behavior\n",
    "  def on_epoch_end(self, epoch, logs={}):\n",
    "    if epoch == 13:\n",
    "      K.set_value(self.alpha, 0.1)\n",
    "      K.set_value(self.beta, 0.8)\n",
    "      K.set_value(self.gamma, 0.1)\n",
    "    if epoch == 23:\n",
    "      K.set_value(self.alpha, 0.1)\n",
    "      K.set_value(self.beta, 0.2)\n",
    "      K.set_value(self.gamma, 0.7)\n",
    "    if epoch == 33:\n",
    "      K.set_value(self.alpha, 0)\n",
    "      K.set_value(self.beta, 0)\n",
    "      K.set_value(self.gamma, 1)\n",
    "\n",
    "#-------- dimensions ---------\n",
    "height, width = 32, 32\n",
    "channel = 3\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    input_shape = (channel, height, width)\n",
    "else:\n",
    "    input_shape = (height, width, channel)\n",
    "#-----------------------------\n",
    "\n",
    "train_size = 50000\n",
    "test_size = 10000\n",
    "\n",
    "#--- coarse 1 classes ---\n",
    "coarse1_classes = 8\n",
    "#--- coarse 2 classes ---\n",
    "coarse2_classes = 20\n",
    "#--- fine classes ---\n",
    "num_classes  = 100\n",
    "\n",
    "batch_size   = 128\n",
    "epochs       = 80\n",
    "\n",
    "#--- file paths ---\n",
    "log_filepath = './tb_log_vgg16_hierarchy_dynamic/'\n",
    "weights_store_filepath = './vgg16_weights_hierarchy_dynamic/'\n",
    "retrain_id = '101'\n",
    "model_name = 'weights_vgg16_dynamic_cifar_100_'+retrain_id+'.h5'\n",
    "model_path = os.path.join(weights_store_filepath, model_name)\n",
    "\n",
    "#----------get VGG16 pre-trained weights--------\n",
    "WEIGHTS_PATH = 'https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg16_weights_tf_dim_ordering_tf_kernels.h5'\n",
    "weights_path = get_file('vgg16_weights_tf_dim_ordering_tf_kernels.h5',\n",
    "                         WEIGHTS_PATH,\n",
    "                         cache_subdir='models')\n",
    "\n",
    "#---------get data---------\n",
    "meta = unpickle(\"meta\")\n",
    "test = unpickle(\"test\")\n",
    "train = unpickle(\"train\")\n",
    "\n",
    "#-------------------- data loading ----------------------\n",
    "x_train = np.reshape(train[b'data'], (train_size, channel, height, width)).transpose(0, 2, 3, 1).astype(\"float32\")\n",
    "x_train = (x_train-np.mean(x_train)) / np.std(x_train)\n",
    "\n",
    "x_test = np.reshape(test[b'data'], (test_size, channel, height, width)).transpose(0, 2, 3, 1).astype(\"float32\")\n",
    "x_test = (x_test-np.mean(x_test)) / np.std(x_test)\n",
    "\n",
    "y_train = np.zeros((train_size, num_classes)).astype('float32')\n",
    "y_c2_train = np.zeros((train_size, coarse2_classes)).astype('float32')\n",
    "\n",
    "y_test = np.zeros((test_size, num_classes)).astype('float32')\n",
    "y_c2_test = np.zeros((test_size, coarse2_classes)).astype('float32')\n",
    "\n",
    "y_train[np.arange(train_size), train[b'fine_labels']] = 1\n",
    "y_c2_train[np.arange(train_size), train[b'coarse_labels']] = 1\n",
    "\n",
    "y_test[np.arange(test_size), test[b'fine_labels']] = 1\n",
    "y_c2_test[np.arange(test_size), test[b'coarse_labels']] = 1\n",
    "\n",
    "c2_to_f = np.zeros((coarse2_classes, num_classes)).astype('float32')\n",
    "fine_unique, fine_unique_indices = np.unique(train[b'fine_labels'], return_index=True)\n",
    "for i in fine_unique_indices:\n",
    "  c2_to_f[train[b'coarse_labels'][i]][train[b'fine_labels'][i]] = 1\n",
    "\n",
    "parent_c2 = {\n",
    "  0:0, 1:0, 2:1, 3:2, \n",
    "  4:1, 5:2, 6:2, 7:3, \n",
    "  8:4, 9:5, 10:5, 11:4, \n",
    "  12:4, 13:3, 14:6, 15:4, \n",
    "  16:4, 17:1, 18:7, 19:7\n",
    "}\n",
    "\n",
    "y_c1_train = np.zeros((y_c2_train.shape[0], coarse1_classes)).astype(\"float32\")\n",
    "y_c1_test = np.zeros((y_c2_test.shape[0], coarse1_classes)).astype(\"float32\")\n",
    "for i in range(y_c1_train.shape[0]):\n",
    "  y_c1_train[i][parent_c2[np.argmax(y_c2_train[i])]] = 1.0\n",
    "for i in range(y_c1_test.shape[0]):\n",
    "  y_c1_test[i][parent_c2[np.argmax(y_c2_test[i])]] = 1.0\n",
    "\n",
    "del(train)\n",
    "del(test)\n",
    "#---------------------------\n",
    "\n",
    "print(\"x_train shape: \", x_train.shape)\n",
    "print(\"x_test shape: \", x_test.shape)\n",
    "\n",
    "print(\"y_train shape: \", y_train.shape)\n",
    "print(\"y_test shape: \", y_test.shape)\n",
    "print(\"y_c1_train shape: \", y_c1_train.shape)\n",
    "print(\"y_c1_test shape: \", y_c1_test.shape)\n",
    "print(\"y_c2_train shape: \", y_c2_train.shape)\n",
    "print(\"y_c2_test shape: \", y_c2_test.shape)\n",
    "\n",
    "#----------------------- model definition ---------------------------\n",
    "alpha = K.variable(value=0.98, dtype=\"float32\", name=\"alpha\") # A1 in paper\n",
    "beta = K.variable(value=0.01, dtype=\"float32\", name=\"beta\") # A2 in paper\n",
    "gamma = K.variable(value=0.01, dtype=\"float32\", name=\"gamma\") # A3 in paper\n",
    "\n",
    "img_input = Input(shape=input_shape, name='input')\n",
    "#--- block 1 ---\n",
    "x = Conv2D(64, (3, 3), activation='relu', padding='same', name='block1_conv1')(img_input)\n",
    "x = BatchNormalization()(x)\n",
    "x = Conv2D(64, (3, 3), activation='relu', padding='same', name='block1_conv2')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = MaxPooling2D((2, 2), strides=(2, 2), name='block1_pool')(x)\n",
    "\n",
    "#--- block 2 ---\n",
    "x = Conv2D(128, (3, 3), activation='relu', padding='same', name='block2_conv1')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Conv2D(128, (3, 3), activation='relu', padding='same', name='block2_conv2')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = MaxPooling2D((2, 2), strides=(2, 2), name='block2_pool')(x)\n",
    "\n",
    "#--- coarse 1 branch ---\n",
    "c_1_bch = Flatten(name='c1_flatten')(x)\n",
    "c_1_bch = Dense(256, activation='relu', name='c1_fc_cifar10_1')(c_1_bch)\n",
    "c_1_bch = BatchNormalization()(c_1_bch)\n",
    "c_1_bch = Dropout(0.5)(c_1_bch)\n",
    "c_1_bch = Dense(256, activation='relu', name='c1_fc2')(c_1_bch)\n",
    "c_1_bch = BatchNormalization()(c_1_bch)\n",
    "c_1_bch = Dropout(0.5)(c_1_bch)\n",
    "c_1_pred = Dense(coarse1_classes, activation='softmax', name='c1_predictions_cifar10')(c_1_bch)\n",
    "\n",
    "#--- block 3 ---\n",
    "x = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv1')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv2')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv3')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = MaxPooling2D((2, 2), strides=(2, 2), name='block3_pool')(x)\n",
    "\n",
    "#--- coarse 2 branch ---\n",
    "c_2_bch = Flatten(name='c2_flatten')(x)\n",
    "c_2_bch = Dense(1024, activation='relu', name='c2_fc_cifar100_1')(c_2_bch)\n",
    "c_2_bch = BatchNormalization()(c_2_bch)\n",
    "c_2_bch = Dropout(0.5)(c_2_bch)\n",
    "c_2_bch = Dense(1024, activation='relu', name='c2_fc2')(c_2_bch)\n",
    "c_2_bch = BatchNormalization()(c_2_bch)\n",
    "c_2_bch = Dropout(0.5)(c_2_bch)\n",
    "c_2_pred = Dense(coarse2_classes, activation='softmax', name='c2_predictions_cifar100')(c_2_bch)\n",
    "\n",
    "#--- block 4 ---\n",
    "x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv1')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv2')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv3')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = MaxPooling2D((2, 2), strides=(2, 2), name='block4_pool')(x)\n",
    "\n",
    "\n",
    "#--- block 5 ---\n",
    "x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv1')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv2')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv3')(x)\n",
    "x = BatchNormalization()(x)\n",
    "\n",
    "#--- fine block ---\n",
    "x = Flatten(name='flatten')(x)\n",
    "x = Dense(4096, activation='relu', name='fc_cifar100_1')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(4096, activation='relu', name='fc_cifar100_2')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "fine_pred = Dense(num_classes, activation='softmax', name='predictions_cifar100')(x)\n",
    "\n",
    "model = Model(img_input, [c_1_pred, c_2_pred, fine_pred], name='vgg16_hierarchy')\n",
    "model.load_weights(weights_path, by_name=True)\n",
    "\n",
    "#----------------------- compile and fit ---------------------------\n",
    "sgd = optimizers.SGD(lr=0.001, momentum=0.9, nesterov=True)\n",
    "model.compile(loss='categorical_crossentropy', \n",
    "              optimizer=sgd, \n",
    "              loss_weights=[alpha, beta, gamma], \n",
    "              # optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])\n",
    "tb_cb = TensorBoard(log_dir=log_filepath, histogram_freq=0)\n",
    "change_lr = LearningRateScheduler(scheduler)\n",
    "change_lw = LossWeightsModifier(alpha, beta, gamma)\n",
    "cbks = [change_lr, tb_cb, change_lw]\n",
    "\n",
    "model.fit(x_train, [y_c1_train, y_c2_train, y_train],\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          callbacks=cbks,\n",
    "          validation_data=(x_test, [y_c1_test, y_c2_test, y_test]))\n",
    "\n",
    "#---------------------------------------------------------------------------------\n",
    "# The following compile() is just a behavior to make sure this model can be saved.\n",
    "# We thought it may be a bug of Keras which cannot save a model compiled with loss_weights parameter\n",
    "#---------------------------------------------------------------------------------\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              # optimizer=keras.optimizers.Adadelta(),\n",
    "              optimizer=sgd, \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.save(model_path)\n",
    "score = model.evaluate(x_test, [y_c1_test, y_c2_test, y_test], verbose=0)\n",
    "print('score is: ', score)\n",
    "Footer\n",
    "© 2023 GitHub, Inc.\n",
    "Footer navigation\n",
    "Terms\n",
    "Privacy\n",
    "Security\n",
    "Status\n",
    "Docs\n",
    "Contact GitHub\n",
    "Pricing\n",
    "API\n",
    "Training\n",
    "Blog\n",
    "About\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "automatic-tagging",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12 (default, Dec 20 2022, 21:33:07) \n[GCC 11.3.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f29be12947edb0fb12a85f03ec93c6b19442e375d04585e5cfb5d674835b1a2c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
